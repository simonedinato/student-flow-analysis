{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c0f0dbd",
   "metadata": {},
   "source": [
    "# Step 4: Employability and Quality Proxies\n",
    "\n",
    "## Objective\n",
    "Add proxies for the \"Quality\" and \"Opportunity\" of the destination, which are key pull factors.\n",
    "\n",
    "## Data Sources\n",
    "1.  **Youth Transition (TRANS)**: Employment rates for recent graduates (aged 25-29).\n",
    "2.  **University Rankings**: (Optional) Presence of top-ranked universities.\n",
    "\n",
    "## Methodology\n",
    "- **Employment Rate**: We use the employment rate of tertiary graduates as a proxy for the *probability* of finding a job after graduation.\n",
    "- **Imputation**: Missing years are imputed using nearest-neighbor interpolation (\u00b11 or \u00b12 years) to maximize coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "863447ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema audit \u2014 unique values\n",
      "- UNIT_MEASURE: 1 unique -> ['PT_POP_SUB']\n",
      "- LABOUR_FORCE_STATUS: 5 unique -> ['EMP', 'NE', 'OLF', 'POP', 'UNE']\n",
      "- SEX: 1 unique -> ['_T']\n",
      "- AGE: 1 unique -> ['Y25T29']\n",
      "- ATTAINMENT_LEV: 6 unique -> ['ISCED11A_0T2', 'ISCED11A_34_44', 'ISCED11A_35_45', 'ISCED11A_3_4', 'ISCED11A_5T8', '_T']\n",
      "Denominator families detected based on measure tokens:\n",
      "  LF tokens: ['<none>']\n",
      "  POP tokens: ['PT_POP_SUB']\n",
      "Filtered TRANS rows: 148\n",
      "emp_rate_dest coverage: 95.83%\n",
      "emp_rate_dest min/median/max: 0.328, 0.421, 0.917\n",
      "emp_source_tag counts:\n",
      "emp_source_tag\n",
      "POP|exact    621\n",
      "NaN           27\n",
      "Name: count, dtype: int64\n",
      "Imputed (\u00b11y/\u00b12y) count: 0\n",
      "Weight sum violations: 0\n",
      "Top 10 destinations by emp_rate_dest:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kl/fcwqs6xs30b3g73_r8l0_q5m0000gn/T/ipykernel_20887/450240572.py:67: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  tertiary_mask = attainment_series.str.contains(tertiary_pattern, case=False, na=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>destination_country_code</th>\n",
       "      <th>destination_country</th>\n",
       "      <th>year</th>\n",
       "      <th>emp_rate_dest</th>\n",
       "      <th>emp_source_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>POL</td>\n",
       "      <td>Poland</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.917449</td>\n",
       "      <td>POP|exact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>POL</td>\n",
       "      <td>Poland</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.917449</td>\n",
       "      <td>POP|exact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>POL</td>\n",
       "      <td>Poland</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.917449</td>\n",
       "      <td>POP|exact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>POL</td>\n",
       "      <td>Poland</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.917449</td>\n",
       "      <td>POP|exact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>POL</td>\n",
       "      <td>Poland</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.917449</td>\n",
       "      <td>POP|exact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>POL</td>\n",
       "      <td>Poland</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.917449</td>\n",
       "      <td>POP|exact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>POL</td>\n",
       "      <td>Poland</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.917449</td>\n",
       "      <td>POP|exact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>POL</td>\n",
       "      <td>Poland</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.917449</td>\n",
       "      <td>POP|exact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>POL</td>\n",
       "      <td>Poland</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.917449</td>\n",
       "      <td>POP|exact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>POL</td>\n",
       "      <td>Poland</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.917449</td>\n",
       "      <td>POP|exact</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    destination_country_code destination_country  year  emp_rate_dest  \\\n",
       "473                      POL              Poland  2022       0.917449   \n",
       "377                      POL              Poland  2022       0.917449   \n",
       "257                      POL              Poland  2022       0.917449   \n",
       "449                      POL              Poland  2022       0.917449   \n",
       "233                      POL              Poland  2022       0.917449   \n",
       "425                      POL              Poland  2022       0.917449   \n",
       "593                      POL              Poland  2022       0.917449   \n",
       "209                      POL              Poland  2022       0.917449   \n",
       "113                      POL              Poland  2022       0.917449   \n",
       "545                      POL              Poland  2022       0.917449   \n",
       "\n",
       "    emp_source_tag  \n",
       "473      POP|exact  \n",
       "377      POP|exact  \n",
       "257      POP|exact  \n",
       "449      POP|exact  \n",
       "233      POP|exact  \n",
       "425      POP|exact  \n",
       "593      POP|exact  \n",
       "209      POP|exact  \n",
       "113      POP|exact  \n",
       "545      POP|exact  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottom 10 destinations by emp_rate_dest:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>destination_country_code</th>\n",
       "      <th>destination_country</th>\n",
       "      <th>year</th>\n",
       "      <th>emp_rate_dest</th>\n",
       "      <th>emp_source_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>AUT</td>\n",
       "      <td>Austria</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.327932</td>\n",
       "      <td>POP|exact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>AUT</td>\n",
       "      <td>Austria</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.327932</td>\n",
       "      <td>POP|exact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>AUT</td>\n",
       "      <td>Austria</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.327932</td>\n",
       "      <td>POP|exact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>AUT</td>\n",
       "      <td>Austria</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.327932</td>\n",
       "      <td>POP|exact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>AUT</td>\n",
       "      <td>Austria</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.327932</td>\n",
       "      <td>POP|exact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>AUT</td>\n",
       "      <td>Austria</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.327932</td>\n",
       "      <td>POP|exact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>AUT</td>\n",
       "      <td>Austria</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.327932</td>\n",
       "      <td>POP|exact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>AUT</td>\n",
       "      <td>Austria</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.327932</td>\n",
       "      <td>POP|exact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>AUT</td>\n",
       "      <td>Austria</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.327932</td>\n",
       "      <td>POP|exact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>AUT</td>\n",
       "      <td>Austria</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.327932</td>\n",
       "      <td>POP|exact</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    destination_country_code destination_country  year  emp_rate_dest  \\\n",
       "529                      AUT             Austria  2022       0.327932   \n",
       "361                      AUT             Austria  2022       0.327932   \n",
       "73                       AUT             Austria  2022       0.327932   \n",
       "97                       AUT             Austria  2022       0.327932   \n",
       "121                      AUT             Austria  2022       0.327932   \n",
       "217                      AUT             Austria  2022       0.327932   \n",
       "457                      AUT             Austria  2022       0.327932   \n",
       "49                       AUT             Austria  2022       0.327932   \n",
       "25                       AUT             Austria  2022       0.327932   \n",
       "385                      AUT             Austria  2022       0.327932   \n",
       "\n",
       "    emp_source_tag  \n",
       "529      POP|exact  \n",
       "361      POP|exact  \n",
       "73       POP|exact  \n",
       "97       POP|exact  \n",
       "121      POP|exact  \n",
       "217      POP|exact  \n",
       "457      POP|exact  \n",
       "49       POP|exact  \n",
       "25       POP|exact  \n",
       "385      POP|exact  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rows': 648, 'coverage_pct': np.float64(95.83), 'min': np.float64(0.328), 'median': np.float64(0.421), 'max': np.float64(0.917), 'imputed_count': 0, 'weight_violations': 0}\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "BASE_DIR = Path(\"/Users/simonedinato/Documents/Classes/Applied Econometrics/Project\")\n",
    "DATA_DIR = BASE_DIR / \"Datasets\"\n",
    "\n",
    "fact_path = DATA_DIR / \"07_fact_tables\" / \"od_fact_table.csv\"\n",
    "trans_path = DATA_DIR / \"04_employability_proxy\" / \"Youth's transition from education to work (TRANS)-2.csv\"\n",
    "\n",
    "# 1) Load inputs\n",
    "fact = pd.read_csv(fact_path)\n",
    "trans = pd.read_csv(trans_path, low_memory=False)\n",
    "\n",
    "# Ensure year is numeric early for downstream joins\n",
    "fact[\"year\"] = pd.to_numeric(fact[\"year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# 2) Schema audit\n",
    "measure_col = \"UNIT_MEASURE\" if \"UNIT_MEASURE\" in trans.columns else \"MEASURE\"\n",
    "attainment_col_candidates = [\"ATTAINMENT_LEV\", \"EDUCATION_LEV\"]\n",
    "attainment_col = next((c for c in attainment_col_candidates if c in trans.columns), None)\n",
    "if attainment_col is None:\n",
    "    raise ValueError(\"No tertiary attainment column found in TRANS input\")\n",
    "\n",
    "def log_unique(df: pd.DataFrame, column: str, limit: int = 10) -> None:\n",
    "    if column not in df.columns:\n",
    "        print(f\"- {column}: column missing\")\n",
    "        return\n",
    "    uniques = pd.unique(df[column].dropna())\n",
    "    preview_vals = sorted(str(u) for u in uniques[:limit])\n",
    "    suffix = \" ...\" if len(uniques) > limit else \"\"\n",
    "    print(f\"- {column}: {len(uniques)} unique -> {preview_vals}{suffix}\")\n",
    "\n",
    "print(\"Schema audit \u2014 unique values\")\n",
    "for col in [measure_col, \"LABOUR_FORCE_STATUS\", \"SEX\", \"AGE\", attainment_col]:\n",
    "    log_unique(trans, col)\n",
    "\n",
    "measure_values = trans[measure_col].dropna().astype(str)\n",
    "lf_tokens = sorted({val for val in measure_values if (\"LF\" in val.upper()) or (\"LABOUR\" in val.upper())})\n",
    "pop_tokens = sorted({val for val in measure_values if \"POP\" in val.upper()})\n",
    "print(\"Denominator families detected based on measure tokens:\")\n",
    "print(f\"  LF tokens: {lf_tokens if lf_tokens else ['<none>']}\")\n",
    "print(f\"  POP tokens: {pop_tokens if pop_tokens else ['<none>']}\")\n",
    "\n",
    "# iso lookup from fact destinations/origins\n",
    "iso_lookup = pd.concat(\n",
    "    [\n",
    "        fact[[\"destination_country_code\", \"destination_country\"]].rename(\n",
    "            columns={\"destination_country_code\": \"country_code\", \"destination_country\": \"country\"}\n",
    "        ),\n",
    "        fact[[\"origin_country_code\", \"origin_country\"]].rename(\n",
    "            columns={\"origin_country_code\": \"country_code\", \"origin_country\": \"country\"}\n",
    "        ),\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ").dropna(subset=[\"country_code\", \"country\"])\n",
    "iso_lookup[\"country\"] = iso_lookup[\"country\"].astype(str).str.strip()\n",
    "iso_lookup[\"country_code\"] = iso_lookup[\"country_code\"].astype(str).str.upper()\n",
    "iso_lookup = iso_lookup.drop_duplicates(subset=[\"country\"]).set_index(\"country\")[\"country_code\"]\n",
    "\n",
    "# 3) Filter to target population\n",
    "attainment_series = trans[attainment_col].astype(str)\n",
    "tertiary_pattern = r\"(ISCED11A_5T8|ISCED11A_5|ISCED11A_6|ISCED11A_7|ISCED11A_8|TERTIARY)\"\n",
    "tertiary_mask = attainment_series.str.contains(tertiary_pattern, case=False, na=False)\n",
    "\n",
    "age_col = \"AGE\" if \"AGE\" in trans.columns else (\"Age\" if \"Age\" in trans.columns else None)\n",
    "if age_col:\n",
    "    age_series = trans[age_col].astype(str).str.upper()\n",
    "    age_priority = {\"Y25T34\", \"Y25T29\", \"Y25T24\", \"Y25T30\", \"Y25\"}\n",
    "    age_mask = age_series.isin(age_priority)\n",
    "    if not age_mask.any():\n",
    "        age_mask = age_series.str.contains(\"25\", na=False)\n",
    "else:\n",
    "    age_mask = True\n",
    "\n",
    "sex_col = \"SEX\" if \"SEX\" in trans.columns else (\"Sex\" if \"Sex\" in trans.columns else None)\n",
    "if sex_col:\n",
    "    sex_series = trans[sex_col].astype(str).str.upper()\n",
    "    sex_mask = sex_series.isin({\"_T\", \"T\", \"TOTAL\"})\n",
    "else:\n",
    "    sex_mask = True\n",
    "\n",
    "lf_status_col = \"LABOUR_FORCE_STATUS\" if \"LABOUR_FORCE_STATUS\" in trans.columns else None\n",
    "if lf_status_col:\n",
    "    lf_status_series = trans[lf_status_col].astype(str).str.upper()\n",
    "    lf_mask = lf_status_series.isin({\"EMP\", \"UNE\"})\n",
    "else:\n",
    "    lf_mask = True\n",
    "\n",
    "edu_status_col = \"EDU_STATUS\" if \"EDU_STATUS\" in trans.columns else None\n",
    "if edu_status_col:\n",
    "    edu_status_series = trans[edu_status_col].astype(str).str.upper()\n",
    "    edu_status_mask = edu_status_series.isin({\"NED\", \"NED_NE\", \"NE\", \"_T\", \"TOTAL\"})\n",
    "else:\n",
    "    edu_status_mask = True\n",
    "\n",
    "measure_series_upper = trans[measure_col].astype(str).str.upper()\n",
    "lf_measure_mask = measure_series_upper.str.contains(\"LF|LABOUR\", regex=True, na=False)\n",
    "pop_measure_mask = measure_series_upper.str.contains(\"POP\", regex=True, na=False)\n",
    "trans[\"denom_family\"] = np.select(\n",
    "    [lf_measure_mask, pop_measure_mask],\n",
    "    [\"LF\", \"POP\"],\n",
    "    default=pd.NA,\n",
    ")\n",
    "denom_mask = trans[\"denom_family\"].isin({\"LF\", \"POP\"})\n",
    "\n",
    "combined_mask = tertiary_mask & age_mask & sex_mask & lf_mask & edu_status_mask & denom_mask\n",
    "filter_cols = [\n",
    "    \"REF_AREA\",\n",
    "    \"Reference area\",\n",
    "    \"TIME_PERIOD\",\n",
    "    \"LABOUR_FORCE_STATUS\",\n",
    "    \"denom_family\",\n",
    "    \"OBS_VALUE\",\n",
    "]\n",
    "trans_filtered = trans.loc[combined_mask, filter_cols].copy()\n",
    "\n",
    "ref_area_clean = trans_filtered[\"REF_AREA\"].astype(str).str.strip()\n",
    "trans_filtered[\"country_code\"] = np.where(ref_area_clean.str.len() == 3, ref_area_clean.str.upper(), np.nan)\n",
    "trans_filtered[\"country_code\"] = trans_filtered[\"country_code\"].fillna(\n",
    "    trans_filtered[\"Reference area\"].astype(str).str.strip().map(iso_lookup)\n",
    ")\n",
    "trans_filtered[\"year\"] = pd.to_numeric(trans_filtered[\"TIME_PERIOD\"], errors=\"coerce\").astype(\"Int64\")\n",
    "trans_filtered[\"LABOUR_FORCE_STATUS\"] = trans_filtered[\"LABOUR_FORCE_STATUS\"].astype(str).str.upper()\n",
    "trans_filtered[\"value\"] = pd.to_numeric(trans_filtered[\"OBS_VALUE\"], errors=\"coerce\")\n",
    "over_pct_mask = trans_filtered[\"value\"] > 1.5\n",
    "trans_filtered.loc[over_pct_mask, \"value\"] = trans_filtered.loc[over_pct_mask, \"value\"] / 100.0\n",
    "trans_filtered[\"value\"] = trans_filtered[\"value\"].clip(lower=0.0, upper=1.0)\n",
    "trans_filtered = trans_filtered.dropna(subset=[\"country_code\", \"year\", \"value\"])\n",
    "print(f\"Filtered TRANS rows: {len(trans_filtered):,}\")\n",
    "\n",
    "# 4) Build tidy matrices per denominator family\n",
    "\n",
    "def build_family(df: pd.DataFrame, family_label: str) -> pd.DataFrame:\n",
    "    subset = df[df[\"denom_family\"] == family_label].copy()\n",
    "    if subset.empty:\n",
    "        return pd.DataFrame(columns=[\"country_code\", \"year\"])\n",
    "    tidy = subset[[\"country_code\", \"year\", \"LABOUR_FORCE_STATUS\", \"value\"]].dropna(\n",
    "        subset=[\"country_code\", \"year\", \"LABOUR_FORCE_STATUS\"]\n",
    "    )\n",
    "    if tidy.empty:\n",
    "        return pd.DataFrame(columns=[\"country_code\", \"year\"])\n",
    "    matrix = (\n",
    "        tidy.pivot_table(\n",
    "            index=[\"country_code\", \"year\"],\n",
    "            columns=\"LABOUR_FORCE_STATUS\",\n",
    "            values=\"value\",\n",
    "            aggfunc=\"median\",\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    matrix.columns.name = None\n",
    "    return matrix\n",
    "\n",
    "lf_matrix = build_family(trans_filtered, \"LF\")\n",
    "pop_matrix = build_family(trans_filtered, \"POP\")\n",
    "\n",
    "if not lf_matrix.empty:\n",
    "    if \"EMP\" not in lf_matrix.columns:\n",
    "        lf_matrix[\"EMP\"] = np.nan\n",
    "    if \"UNE\" not in lf_matrix.columns:\n",
    "        lf_matrix[\"UNE\"] = np.nan\n",
    "    lf_matrix[\"emp_lf\"] = np.nan\n",
    "    denom = lf_matrix[\"EMP\"] + lf_matrix[\"UNE\"]\n",
    "    ratio_mask = lf_matrix[\"EMP\"].notna() & lf_matrix[\"UNE\"].notna() & (denom > 0)\n",
    "    lf_matrix.loc[ratio_mask, \"emp_lf\"] = lf_matrix.loc[ratio_mask, \"EMP\"] / denom[ratio_mask]\n",
    "    fallback_mask = ~ratio_mask & lf_matrix[\"EMP\"].notna()\n",
    "    lf_matrix.loc[fallback_mask, \"emp_lf\"] = lf_matrix.loc[fallback_mask, \"EMP\"]\n",
    "    lf_matrix[\"emp_lf\"] = lf_matrix[\"emp_lf\"].clip(lower=0.0, upper=1.0)\n",
    "    lf_ready = lf_matrix[[\"country_code\", \"year\", \"emp_lf\"]].dropna(subset=[\"emp_lf\"])\n",
    "else:\n",
    "    lf_ready = pd.DataFrame(columns=[\"country_code\", \"year\", \"emp_lf\"])\n",
    "\n",
    "if not pop_matrix.empty:\n",
    "    if \"EMP\" not in pop_matrix.columns:\n",
    "        pop_matrix[\"EMP\"] = np.nan\n",
    "    pop_matrix[\"emp_pop\"] = pop_matrix[\"EMP\"].clip(lower=0.0, upper=1.0)\n",
    "    pop_ready = pop_matrix[[\"country_code\", \"year\", \"emp_pop\"]].dropna(subset=[\"emp_pop\"])\n",
    "else:\n",
    "    pop_ready = pd.DataFrame(columns=[\"country_code\", \"year\", \"emp_pop\"])\n",
    "\n",
    "# 5-6) Nearest-year smoothing helpers\n",
    "\n",
    "def smooth_variant(\n",
    "    source_df: pd.DataFrame,\n",
    "    value_col: str,\n",
    "    prefix: str,\n",
    "    key_pairs: list[tuple[str, int]],\n",
    ") -> pd.DataFrame:\n",
    "    expected_cols = [\"country_code\", \"year\", value_col]\n",
    "    if source_df.empty or not all(col in source_df.columns for col in expected_cols):\n",
    "        return pd.DataFrame(\n",
    "            columns=[\"destination_country_code\", \"year\", f\"{prefix.lower()}_value\", f\"{prefix.lower()}_tag\", f\"{prefix.lower()}_imputed\"]\n",
    "        )\n",
    "    mapping = (\n",
    "        source_df.set_index([\"country_code\", \"year\"])[value_col]\n",
    "        .dropna()\n",
    "        .to_dict()\n",
    "    )\n",
    "    if not mapping:\n",
    "        return pd.DataFrame(\n",
    "            columns=[\"destination_country_code\", \"year\", f\"{prefix.lower()}_value\", f\"{prefix.lower()}_tag\", f\"{prefix.lower()}_imputed\"]\n",
    "        )\n",
    "    records: list[dict] = []\n",
    "    for code, year in key_pairs:\n",
    "        value = None\n",
    "        tag = None\n",
    "        imputed = 0\n",
    "        key = (code, year)\n",
    "        if key in mapping:\n",
    "            value = mapping[key]\n",
    "            tag = f\"{prefix}|exact\"\n",
    "        else:\n",
    "            for gap in (1, 2):\n",
    "                candidates = []\n",
    "                for sign in (-gap, gap):\n",
    "                    candidate_key = (code, year + sign)\n",
    "                    if candidate_key in mapping:\n",
    "                        candidates.append(mapping[candidate_key])\n",
    "                if candidates:\n",
    "                    value = float(np.mean(candidates))\n",
    "                    tag = f\"{prefix}|\u00b1{gap}y\"\n",
    "                    imputed = 1\n",
    "                    break\n",
    "        if value is not None:\n",
    "            value = float(np.clip(value, 0.0, 1.0))\n",
    "            records.append(\n",
    "                {\n",
    "                    \"destination_country_code\": code,\n",
    "                    \"year\": year,\n",
    "                    f\"{prefix.lower()}_value\": value,\n",
    "                    f\"{prefix.lower()}_tag\": tag,\n",
    "                    f\"{prefix.lower()}_imputed\": imputed,\n",
    "                }\n",
    "            )\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "dest_keys_df = fact[[\"destination_country_code\", \"year\"]].copy()\n",
    "dest_keys_df = dest_keys_df.dropna(subset=[\"destination_country_code\", \"year\"]).drop_duplicates()\n",
    "dest_key_pairs = list(dest_keys_df.itertuples(index=False, name=None))\n",
    "\n",
    "lf_assign = smooth_variant(lf_ready, \"emp_lf\", \"LF\", dest_key_pairs)\n",
    "pop_assign = smooth_variant(pop_ready, \"emp_pop\", \"POP\", dest_key_pairs)\n",
    "if not lf_assign.empty:\n",
    "    lf_assign[\"lf_imputed\"] = lf_assign[\"lf_imputed\"].astype(\"Int64\")\n",
    "if not pop_assign.empty:\n",
    "    pop_assign[\"pop_imputed\"] = pop_assign[\"pop_imputed\"].astype(\"Int64\")\n",
    "\n",
    "dest_table = dest_keys_df.merge(lf_assign, how=\"left\", on=[\"destination_country_code\", \"year\"])\n",
    "dest_table = dest_table.merge(pop_assign, how=\"left\", on=[\"destination_country_code\", \"year\"])\n",
    "lf_mask_final = dest_table.get(\"lf_value\").notna() if \"lf_value\" in dest_table.columns else pd.Series(False, index=dest_table.index)\n",
    "pop_mask_final = ~lf_mask_final & dest_table.get(\"pop_value\").notna() if \"pop_value\" in dest_table.columns else pd.Series(False, index=dest_table.index)\n",
    "\n",
    "dest_table[\"emp_rate_dest_final\"] = dest_table.get(\"lf_value\")\n",
    "dest_table.loc[pop_mask_final, \"emp_rate_dest_final\"] = dest_table.loc[pop_mask_final, \"pop_value\"]\n",
    "\n",
    "dest_table[\"emp_source_tag\"] = dest_table.get(\"lf_tag\")\n",
    "dest_table.loc[pop_mask_final, \"emp_source_tag\"] = dest_table.loc[pop_mask_final, \"pop_tag\"]\n",
    "\n",
    "dest_table[\"emp_rate_imputed\"] = pd.NA\n",
    "if \"lf_imputed\" in dest_table.columns:\n",
    "    dest_table.loc[lf_mask_final, \"emp_rate_imputed\"] = dest_table.loc[lf_mask_final, \"lf_imputed\"].fillna(0).astype(int)\n",
    "if \"pop_imputed\" in dest_table.columns:\n",
    "    dest_table.loc[pop_mask_final, \"emp_rate_imputed\"] = dest_table.loc[pop_mask_final, \"pop_imputed\"].fillna(0).astype(int)\n",
    "dest_table[\"emp_rate_imputed\"] = dest_table[\"emp_rate_imputed\"].astype(\"Int64\")\n",
    "\n",
    "dest_table = dest_table[[\"destination_country_code\", \"year\", \"emp_rate_dest_final\", \"emp_source_tag\", \"emp_rate_imputed\"]]\n",
    "\n",
    "# 7-8) Merge into fact\n",
    "cols_to_drop = [\n",
    "    \"emp_rate_dest\",\n",
    "    \"emp_rate_dest_missing\",\n",
    "    \"emp_rate_imputed\",\n",
    "    \"emp_source_tag\",\n",
    "    \"emp_logit\",\n",
    "    \"emp_z\",\n",
    "]\n",
    "fact = fact.drop(columns=[col for col in cols_to_drop if col in fact.columns])\n",
    "\n",
    "fact = fact.merge(dest_table, on=[\"destination_country_code\", \"year\"], how=\"left\")\n",
    "fact[\"emp_rate_dest\"] = fact[\"emp_rate_dest_final\"].clip(lower=0.0, upper=1.0)\n",
    "fact.drop(columns=[\"emp_rate_dest_final\"], inplace=True)\n",
    "fact[\"emp_rate_imputed\"] = fact[\"emp_rate_imputed\"].where(fact[\"emp_rate_dest\"].notna(), pd.NA).astype(\"Int64\")\n",
    "\n",
    "emp_rate_numeric = pd.to_numeric(fact[\"emp_rate_dest\"], errors=\"coerce\")\n",
    "fact[\"emp_rate_dest\"] = emp_rate_numeric\n",
    "winsorized = emp_rate_numeric.clip(lower=0.02, upper=0.98)\n",
    "fact[\"emp_logit\"] = np.where(\n",
    "    emp_rate_numeric.notna(),\n",
    "    np.log(winsorized / (1 - winsorized)),\n",
    "    np.nan,\n",
    ")\n",
    "\n",
    "\n",
    "def zscore(series: pd.Series) -> pd.Series:\n",
    "    mean = series.mean()\n",
    "    std = series.std(ddof=0)\n",
    "    if pd.isna(std) or std == 0:\n",
    "        return pd.Series(np.nan, index=series.index)\n",
    "    return (series - mean) / std\n",
    "\n",
    "fact[\"emp_z\"] = fact.groupby(\"year\")[\"emp_rate_dest\"].transform(zscore)\n",
    "\n",
    "# 9) QC checks\n",
    "coverage = fact[\"emp_rate_dest\"].notna().mean()\n",
    "emp_stats = fact[\"emp_rate_dest\"].agg([\"min\", \"median\", \"max\"])\n",
    "source_counts = fact[\"emp_source_tag\"].value_counts(dropna=False)\n",
    "imputed_total = fact[\"emp_rate_imputed\"].fillna(0).astype(int).sum()\n",
    "\n",
    "print(f\"emp_rate_dest coverage: {coverage:.2%}\")\n",
    "print(f\"emp_rate_dest min/median/max: {emp_stats['min']:.3f}, {emp_stats['median']:.3f}, {emp_stats['max']:.3f}\")\n",
    "print(\"emp_source_tag counts:\")\n",
    "print(source_counts)\n",
    "print(f\"Imputed (\u00b11y/\u00b12y) count: {imputed_total}\")\n",
    "\n",
    "weight_check = (\n",
    "    fact.groupby([\"origin_country_code\", \"year\"])[\"weight_od\"].sum().reset_index(name=\"w_sum\")\n",
    ")\n",
    "violations = weight_check[~weight_check[\"w_sum\"].between(0.999, 1.001)]\n",
    "print(\"Weight sum violations:\", len(violations))\n",
    "if not violations.empty:\n",
    "    display(violations.head())\n",
    "\n",
    "top10 = fact[fact[\"emp_rate_dest\"].notna()].sort_values(\"emp_rate_dest\", ascending=False).head(10)\n",
    "bottom10 = fact[fact[\"emp_rate_dest\"].notna()].sort_values(\"emp_rate_dest\", ascending=True).head(10)\n",
    "print(\"Top 10 destinations by emp_rate_dest:\")\n",
    "display(top10[[\"destination_country_code\", \"destination_country\", \"year\", \"emp_rate_dest\", \"emp_source_tag\"]])\n",
    "print(\"Bottom 10 destinations by emp_rate_dest:\")\n",
    "display(bottom10[[\"destination_country_code\", \"destination_country\", \"year\", \"emp_rate_dest\", \"emp_source_tag\"]])\n",
    "\n",
    "# 10) Persist\n",
    "fact = fact.drop_duplicates()\n",
    "fact.to_csv(fact_path, index=False)\n",
    "\n",
    "print(\n",
    "    {\n",
    "        \"rows\": len(fact),\n",
    "        \"coverage_pct\": round(coverage * 100, 2),\n",
    "        \"min\": round(emp_stats[\"min\"], 3),\n",
    "        \"median\": round(emp_stats[\"median\"], 3),\n",
    "        \"max\": round(emp_stats[\"max\"], 3),\n",
    "        \"imputed_count\": int(imputed_total),\n",
    "        \"weight_violations\": int(len(violations)),\n",
    "    }\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}